{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Trends Tutorial\n",
    "\n",
    "\n",
    "Google Trends is a website for investigating how different Google keyword searches have trended over time. There is so much you can do with this resource, from comparing the interest in different topics by state to discovering new trends in shopping searches.\n",
    "\n",
    "### To get started, first check out the [Google Trends website](https://trends.google.com/trends/)\n",
    "  - Enter some keyword search terms to see trends over time (you can compare up to 5 terms)\n",
    "  - You can filter on date range, geography, search categories (e.g. Shopping Search) and types (e.g News, Images, etc, all the normal types of Google searches you can do)\n",
    "  - Google returns daily or weekly aggregations (you can't choose) based on how long the time frame is\n",
    "\n",
    "### A few important caveats to bear in mind with Google Trends\n",
    "  - Google provides *sampled* data, so if you pull the same data twice there may be a small amount of variability.\n",
    "  - The data is scaled, so that the maximum value in any requested dataset will be 100. So if you separately pull reports for different keywords, you won't be able to tell relative popularity between them (but you can pull multiple keywords at a time to compare their search interest directly)\n",
    "  - The search interest values provided are NOT the same as search *volume*. They are search interest *relative to all Google searches* during the time period and geography you are requesting. Since the overall usage of Google has grown over the years, this means that a search term that has constant search *volume* will show up as having decreasing search *interest* over time (e.g. \"computer\"). A term whose search volume has grown in pace with the internet's growth will show up as having a relatively constant search interest (e.g. \"life\").\n",
    "  \n",
    "### PyTrends\n",
    "Google does not supply an API for Google Trends, but some lovely folks at General Mills have created the **PyTrends** package for pulling in this data from Python. Documentation is in the README of the GitLab repo [here](https://github.com/GeneralMills/pytrends). You can install PyTrends by running:\n",
    "\n",
    "```\n",
    "pip install pytrends\n",
    "```\n",
    "\n",
    "Let's get started by importing the above package into this Jupyter Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pytrends.request import TrendReq\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set a nice plotting style\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('super_secrets.txt', 'r') as f:\n",
    "    secrets = f.read().splitlines() \n",
    "username, password = secrets\n",
    "\n",
    "connector = TrendReq(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enter your Google username and password\n",
    "\n",
    "# connector = TrendReq('username', 'password')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download some data\n",
    "\n",
    "Now that you are logged into Google, you can build a \"payload\" to specify what data you want to download. PyTrends returns the data as a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_search_terms = ['sklearn']  # list with up to 5 items\n",
    "\n",
    "connector.build_payload(my_search_terms)\n",
    "df = connector.interest_over_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connector.build_payload?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building advanced requests\n",
    "\n",
    "By default the `build_payload()` method will give you 5 years of worldwide data, with no filters applied on search type or category. There are many categories you can choose from by setting the `cat` parameter (default `cat=0` means all categories, i.e. a normal Google search); a few other options are:\n",
    "- Shopping: `cat=18`\n",
    "- Sports: `cat=20`\n",
    "- Travel: `cat=67`\n",
    "    \n",
    "Similary, the default setting of `gprop=''` gives you regular Web Search data. You can filter to other types of searches by setting `gprop` to:\n",
    "- 'images'\n",
    "- 'news'\n",
    "- 'youtube'\n",
    "- 'froogle' (Google Shopping)\n",
    "\n",
    "Geography can be specified with the `geo` parameter, e.g. `geo='US'` will give you search interest in the U.S.\n",
    "\n",
    "Timeframe is a bit tricky. If you need to be more specific than the default 5 year window, I recommend giving custom start and end dates. The structure for this is to set the `timeframe` parameter to a string with a space between start and end dates: `'yyyy-mm-dd yyyy-mm-dd'`. See the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Google Shopping searches for skis and snowboards in the US for last three years\n",
    "connector.build_payload(['skis', 'snowboards'], cat=0, timeframe='2014-08-01 2017-08-01',\n",
    "                        geo='US', gprop='froogle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = connector.interest_over_time()\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "connector.build_payload(['whistler', 'snowbird'], geo='US')\n",
    "df = connector.interest_over_time()\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "connector.interest_by_region()  # check out hawaii!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "related = connector.related_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "related.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "related['sklearn']['top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "related['sklearn']['rising']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
